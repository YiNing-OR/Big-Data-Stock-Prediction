{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from LinearRegression import run_linear_regression\n",
    "from RandomForestRegressor_New import RandomForestRegressor\n",
    "from RandomForestRegressor import RandomForestRegressor_Base\n",
    "from XGBoostRegressor import XGBoostRegressor \n",
    "from DecisionTreeRegressor import DecisionTreeRegressor\n",
    "import numpy as np\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from RidgeLinearRegression import run_ridge_regression\n",
    "from LassoLinearRegression import run_lasso_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news = pd.read_csv('/Users/oryining/Documents/NUS MComp/Semester 2/CS5344 - Big Data Analytics Technology/CS5344_Project/1. Data Retrieval and Processing of News and Stock Prices/final_sample_finbert.csv')\n",
    "columns_to_select = ['Date_hourly', 'weighted_positive_fb', 'weighted_negative_fb', 'weighted_neutral_fb','weighted_DocTone']\n",
    "df_news = df_news[columns_to_select]\n",
    "df_news['Date_hourly'] = df_news['Date_hourly'].astype(str).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stock_price = pd.read_csv('/Users/oryining/Documents/NUS MComp/Semester 2/CS5344 - Big Data Analytics Technology/CS5344_Project/1. Data Retrieval and Processing of News and Stock Prices/us_2024_ticker combined versions/SPY_Combined_WithPriceChange.csv',index_col=0)\n",
    "df_stock_price\n",
    "df_stock_price['Date'] = df_stock_price['Date'].astype(str)\n",
    "df_stock_price['Time'] = df_stock_price['Time'].astype(str).str.zfill(6)\n",
    "\n",
    "df_stock_price['Date_hourly'] = '20' + df_stock_price['Date'] + df_stock_price['Time'].str[:2]\n",
    "df_stock_price=df_stock_price.iloc[:, -2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pct_Change</th>\n",
       "      <th>Date_hourly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023297</td>\n",
       "      <td>2024010209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.134456</td>\n",
       "      <td>2024010210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.318019</td>\n",
       "      <td>2024010211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.116232</td>\n",
       "      <td>2024010212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.116365</td>\n",
       "      <td>2024010213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>0.063408</td>\n",
       "      <td>2024101811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>0.128440</td>\n",
       "      <td>2024101812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>-0.015393</td>\n",
       "      <td>2024101813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>0.059876</td>\n",
       "      <td>2024101814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>-0.037620</td>\n",
       "      <td>2024101815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1411 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Pct_Change Date_hourly\n",
       "0       0.023297  2024010209\n",
       "1      -0.134456  2024010210\n",
       "2       0.318019  2024010211\n",
       "3      -0.116232  2024010212\n",
       "4      -0.116365  2024010213\n",
       "...          ...         ...\n",
       "1406    0.063408  2024101811\n",
       "1407    0.128440  2024101812\n",
       "1408   -0.015393  2024101813\n",
       "1409    0.059876  2024101814\n",
       "1410   -0.037620  2024101815\n",
       "\n",
       "[1411 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stock_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the datasets on the 'Date_hourly' column using an inner join to keep only matching rows\n",
    "merged_df = pd.merge(df_news, df_stock_price, on='Date_hourly', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv('/Users/oryining/Documents/NUS MComp/Semester 2/CS5344 - Big Data Analytics Technology/CS5344_Project/1. Data Retrieval and Processing of News and Stock Prices/final_dataset.csv',index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split and creating of x_train, x_val, x and y_train, y_val, y_test\n",
    "Y = merged_df[['Pct_Change']]  \n",
    "X = merged_df[['weighted_positive_fb', 'weighted_negative_fb', 'weighted_neutral_fb','weighted_DocTone']]  \n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(X, Y, test_size=0.2, random_state=1616)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.25, random_state=1616)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Models to input to Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearRegressionScratch():\n",
    "    #Linear Regresion Model\n",
    "    lin_reg_model = run_linear_regression(x_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    lin_reg_predicted_values = lin_reg_model.predict(x_test.values)\n",
    "\n",
    "    train_score = lin_reg_model.score(x_train.values, y_train.values.ravel())\n",
    "    test_score = lin_reg_model.score(x_test.values, y_test.values.ravel())\n",
    "    train_rmse = lin_reg_model.rmse(x_train.values, y_train.values.ravel())\n",
    "    test_rmse = lin_reg_model.rmse(x_test.values, y_test.values.ravel())\n",
    "\n",
    "    print(f\"Training RMSE: {train_rmse}\")\n",
    "    print(f\"Test RMSE: {test_rmse}\")\n",
    "\n",
    "    print(f\"Training R2: {train_score}\")\n",
    "    print(f\"Test R2: {test_score}\")\n",
    "\n",
    "\n",
    "    return lin_reg_predicted_values,lin_reg_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RidgeRegressionScratch():\n",
    "    #Ridge Regresion Model\n",
    "    rig_reg_model = run_ridge_regression(x_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    rig_reg_predicted_values = rig_reg_model.predict(x_test.values)\n",
    "\n",
    "    train_score = rig_reg_model.score(x_train.values, y_train.values.ravel())\n",
    "    test_score = rig_reg_model.score(x_test.values, y_test.values.ravel())\n",
    "    train_rmse = rig_reg_model.rmse(x_train.values, y_train.values.ravel())\n",
    "    test_rmse = rig_reg_model.rmse(x_test.values, y_test.values.ravel())\n",
    "\n",
    "    print(f\"Training RMSE: {train_rmse}\")\n",
    "    print(f\"Test RMSE: {test_rmse}\")\n",
    "\n",
    "    print(f\"Training R2: {train_score}\")\n",
    "    print(f\"Test R2: {test_score}\")\n",
    "\n",
    "\n",
    "    return rig_reg_predicted_values,rig_reg_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Regressor \n",
    "def RandomForestRegressorScratch_New():\n",
    "\n",
    "    rfr_model = RandomForestRegressor(n_estimators=5, max_depth=5, min_samples_split=8)\n",
    "    rfr_model.fit(x_train.values, y_train.values.ravel())\n",
    "    rfr_predicted_values = rfr_model.predict(x_test.values)\n",
    "\n",
    "    train_score = rfr_model.score(x_train.values, y_train.values.ravel())\n",
    "    test_score = rfr_model.score(x_test.values, y_test.values.ravel())\n",
    "    train_rmse = rfr_model.rmse(x_train.values, y_train.values.ravel())\n",
    "    test_rmse = rfr_model.rmse(x_test.values, y_test.values.ravel())\n",
    "\n",
    "    print(f\"Training RMSE: {train_rmse}\")\n",
    "    print(f\"Test RMSE: {test_rmse}\")\n",
    "\n",
    "\n",
    "    print(f\"Training R2: {train_score}\")\n",
    "    print(f\"Test R2: {test_score}\")\n",
    "\n",
    "    return rfr_predicted_values,rfr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Regressor \n",
    "def RandomForestRegressorScratch_Base():\n",
    "\n",
    "    rfr_model = RandomForestRegressor_Base(n_estimators=5, max_depth=5, min_samples_split=8)\n",
    "    rfr_model.fit(x_train.values, y_train.values.ravel())\n",
    "    rfr_predicted_values = rfr_model.predict(x_test.values)\n",
    "\n",
    "    train_score = rfr_model.score(x_train.values, y_train.values.ravel())\n",
    "    test_score = rfr_model.score(x_test.values, y_test.values.ravel())\n",
    "    train_rmse = rfr_model.rmse(x_train.values, y_train.values.ravel())\n",
    "    test_rmse = rfr_model.rmse(x_test.values, y_test.values.ravel())\n",
    "\n",
    "    print(f\"Training RMSE: {train_rmse}\")\n",
    "    print(f\"Test RMSE: {test_rmse}\")\n",
    "\n",
    "\n",
    "    print(f\"Training R2: {train_score}\")\n",
    "    print(f\"Test R2: {test_score}\")\n",
    "\n",
    "    return rfr_predicted_values,rfr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBOOST\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate evaluation metrics\n",
    "def evaluate_metrics(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    \n",
    "    return {\n",
    "        \"Mean Absolute Error (MAE)\": mae,\n",
    "        \"Mean Squared Error (MSE)\": mse,\n",
    "        \"Root Mean Squared Error (RMSE)\": rmse,\n",
    "        \"R-Squared (R2)\": r2\n",
    "    }\n",
    "\n",
    "# Main XGBoost Regressor function with feature engineering and extended evaluation\n",
    "def XGBoostRegressorScratch():\n",
    "    # Apply feature engineering on training and test data\n",
    "\n",
    "    # Initialize the model with regularization parameters\n",
    "    xgb_model = XGBoostRegressor(n_estimators=100, learning_rate=0.2, max_depth=8)\n",
    "    xgb_model.fit(x_train.values, y_train.values.ravel())\n",
    "\n",
    "    # Predictions on the test set\n",
    "    xgb_predicted_values = xgb_model.predict(x_test.values)\n",
    "\n",
    "    # Calculate training metrics\n",
    "    train_metrics = evaluate_metrics(xgb_model, x_train.values, y_train.values.ravel())\n",
    "    test_metrics = evaluate_metrics(xgb_model, x_test.values, y_test.values.ravel())\n",
    "\n",
    "    # Print training metrics\n",
    "    print(\"Training Metrics:\")\n",
    "    for metric, value in train_metrics.items():\n",
    "        print(f\"{metric}: {value}\")\n",
    "\n",
    "    # Print test metrics\n",
    "    print(\"\\nTest Metrics:\")\n",
    "    for metric, value in test_metrics.items():\n",
    "        print(f\"{metric}: {value}\")\n",
    "\n",
    "    return xgb_predicted_values, xgb_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Regressor\n",
    "def DecisionTreeScratch_New():\n",
    "\n",
    "    dtr_model = DecisionTreeRegressor(max_depth=5,min_samples_split=2, min_samples_leaf=1, max_features=1, min_impurity_decrease=0.0)\n",
    "    dtr_model.fit(x_train.values, y_train.values.ravel())\n",
    "    dtr_predicted_values = dtr_model.predict(x_test.values)\n",
    "\n",
    "    train_score = dtr_model.score(x_train.values, y_train.values.ravel())\n",
    "    test_score = dtr_model.score(x_test.values, y_test.values.ravel())\n",
    "    train_rmse = dtr_model.rmse(x_train.values, y_train.values.ravel())\n",
    "    test_rmse = dtr_model.rmse(x_test.values, y_test.values.ravel())\n",
    "\n",
    "    print(f\"Training RMSE: {train_rmse}\")\n",
    "    print(f\"Test RMSE: {test_rmse}\")\n",
    "\n",
    "\n",
    "    print(f\"Training R2: {train_score}\")\n",
    "    print(f\"Test R2: {test_score}\")\n",
    "\n",
    "    return dtr_predicted_values,dtr_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============Self-Built Linear Regresion Outputs=====================\n",
      "Training RMSE: 1.6002287087830942\n",
      "Test RMSE: 1.6488173264395807\n",
      "Training R2: 0.6486776666295189\n",
      "Test R2: 0.6508259456420558\n"
     ]
    }
   ],
   "source": [
    "print(\"===============Self-Built Linear Regresion Outputs=====================\")\n",
    "lin_reg_predicted_values, lin_reg_model= LinearRegressionScratch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============Self-Built Linear Regresion Outputs=====================\n",
      "Training RMSE: 1.600238226348562\n",
      "Test RMSE: 1.6489940001263197\n",
      "Training R2: 0.6486734875478246\n",
      "Test R2: 0.6507511124005598\n"
     ]
    }
   ],
   "source": [
    "print(\"===============Self-Built Linear Regresion Outputs=====================\")\n",
    "rig_reg_predicted_values,rig_reg_model = RidgeRegressionScratch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============Decision Tree Regresion Outputs=====================\n",
      "Training RMSE: 1.3945399896014103\n",
      "Test RMSE: 1.449995499423998\n",
      "Training R2: 0.7331890873001388\n",
      "Test R2: 0.7299587006041339\n"
     ]
    }
   ],
   "source": [
    "print(\"===============Decision Tree Regresion Outputs=====================\")\n",
    "dtr_predicted_values,dtr_model= DecisionTreeScratch_New()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============Self-Built RandomForest Regressor Outputs================\n",
      "Training RMSE: 1.3600836055859942\n",
      "Test RMSE: 1.4035492659763766\n",
      "Training R2: 0.7462109648015143\n",
      "Test R2: 0.7469815427244613\n"
     ]
    }
   ],
   "source": [
    "print(\"===============Self-Built RandomForest Regressor Outputs================\")\n",
    "rfr_predicted_values,rfr_model = RandomForestRegressorScratch_New()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============Self-Built RandomForest Regressor Outputs================\n",
      "Training RMSE: 1.3654782704138042\n",
      "Test RMSE: 1.4009536056603427\n",
      "Training R2: 0.7441937035044749\n",
      "Test R2: 0.7479165190774631\n"
     ]
    }
   ],
   "source": [
    "print(\"===============Self-Built RandomForest Regressor Outputs================\")\n",
    "rfr_predicted_values_base,rfr_model_base = RandomForestRegressorScratch_Base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============Self-Built XGBoost Regressor Baseline Outputs============\n",
      "Training Metrics:\n",
      "Mean Absolute Error (MAE): 0.5846906640670294\n",
      "Mean Squared Error (MSE): 0.5582729784685998\n",
      "Root Mean Squared Error (RMSE): 0.7471766715232748\n",
      "R-Squared (R2): 0.9234071462577788\n",
      "\n",
      "Test Metrics:\n",
      "Mean Absolute Error (MAE): 1.220553648024484\n",
      "Mean Squared Error (MSE): 2.22870976169976\n",
      "Root Mean Squared Error (RMSE): 1.492886386065517\n",
      "R-Squared (R2): 0.7137467699868412\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"===============Self-Built XGBoost Regressor Baseline Outputs============\")\n",
    "xgb_predicted_values,xgb_model = XGBoostRegressorScratch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placing All Models in Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model predictions from X_test that are combined to be passed into the ensemble\n",
    "y_pred_stacked_predictions = np.column_stack((lin_reg_predicted_values, rfr_predicted_values,xgb_predicted_values,dtr_predicted_values))\n",
    "y_pred_stacked_predictions_df = pd.DataFrame(y_pred_stacked_predictions, columns=['reg_pred1', 'rf_pred2','xgboost_pred3','dtr_pred4'])\n",
    "\n",
    "#Generating Y_validation values from X_values\n",
    "y_val_input_reg_model = lin_reg_model.predict(x_val.values)\n",
    "y_val_input_rf_model=rfr_model.predict(x_val.values)\n",
    "y_val_input_xgb_model=xgb_model.predict(x_val.values)\n",
    "y_val_input_dtr_model=dtr_model.predict(x_val.values)\n",
    "\n",
    "y_val_input_model_predictions = np.column_stack((y_val_input_reg_model, y_val_input_rf_model,y_val_input_xgb_model,y_val_input_dtr_model))\n",
    "y_val_input_model_predictions_df = pd.DataFrame(y_val_input_model_predictions, columns=['reg_pred1', 'rf_pred2','xgboost_pred3','dtr_pred4'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============Self-Built Ensemble Model============================\n",
      "Validation RMSE: 1.3809851813825114\n",
      "[-0.05696452  0.93635444  0.04511427  0.09778915]\n",
      "Validation R2: 0.6703310390605548\n",
      "Ensemble Model - Linear Reg, RF, XGBoost, Decision tree Models stacked on Linear Reg Model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ensemble_model= run_linear_regression(y_pred_stacked_predictions_df,y_test) # Predicted Values of the Models, and y_test is the Y variable\n",
    "y_ensemble = ensemble_model.predict(y_val_input_model_predictions_df) \n",
    "\n",
    "val_rmse = root_mean_squared_error(y_ensemble, y_val)\n",
    "r2 = r2_score(y_ensemble, y_val)\n",
    "\n",
    "print(\"===============Self-Built Ensemble Model============================\")\n",
    "print(f'Validation RMSE: {val_rmse}')\n",
    "print(ensemble_model.weights)\n",
    "print(f'Validation R2: {r2}')\n",
    "\n",
    "print(\"Ensemble Model - Linear Reg, RF, XGBoost, Decision tree Models stacked on Linear Reg Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============Self-Built Ensemble Model (Ridge)=====================\n",
      "Validation RMSE: 1.3809056716927761\n",
      "Validation R2: 0.7455387053320742\n",
      "Ensemble Model Weights (Coefficients): [-0.05626572  0.93155882  0.04665028  0.1004569 ]\n",
      "Ensemble Model - Linear Reg, RF, XGBoost, Decision tree Models stacked on Ridge Reg Model\n"
     ]
    }
   ],
   "source": [
    "# Initialize Ridge regression model for the ensemble\n",
    "ridge_model = run_ridge_regression(y_pred_stacked_predictions_df, y_test)\n",
    "\n",
    "# Make predictions with the trained Ridge model on the validation set\n",
    "y_ensemble = ridge_model.predict(y_val_input_model_predictions_df)\n",
    "\n",
    "# Evaluate the model\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_ensemble))\n",
    "r2 = r2_score(y_val, y_ensemble)\n",
    "\n",
    "# Print results\n",
    "print(\"===============Self-Built Ensemble Model (Ridge)=====================\")\n",
    "print(f'Validation RMSE: {val_rmse}')\n",
    "print(f'Validation R2: {r2}')\n",
    "\n",
    "print(f'Ensemble Model Weights (Coefficients): {ridge_model.weights}')\n",
    "\n",
    "print(\"Ensemble Model - Linear Reg, RF, XGBoost, Decision tree Models stacked on Ridge Reg Model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============Self-Built Ensemble Model (Ridge)=====================\n",
      "Best number of splits (n_splits): 3\n",
      "Best alpha: 1.5\n",
      "Validation RMSE: 1.3808668930392258\n",
      "Validation R2: 0.7455529967178481\n",
      "Ensemble Model Weights (Coefficients): [[-0.055919    0.92918945  0.04741014  0.1017725 ]]\n",
      "Ensemble Model - Linear Reg, RF, XGBoost, Decision tree Models stacked on Ridge Reg Model w Hyper Parameter Tuning\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define parameter grid for alpha\n",
    "parameters = {'alpha': [0.01, 0.1, 1, 1.5, 1.6, 3, 3.01, 3.05, 3.1, 3.5, 5, 10, 100, 100]}\n",
    "\n",
    "# List of n_splits to try\n",
    "n_splits_options = [3, 5, 7, 10, 20, 30]\n",
    "best_score = float(\"inf\")\n",
    "best_n_splits = None\n",
    "best_alpha = None\n",
    "best_model = None\n",
    "\n",
    "# Loop through different values of n_splits\n",
    "for n_splits in n_splits_options:\n",
    "    # Set up KFold with the current number of splits\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Set up GridSearchCV with the current KFold\n",
    "    ridge_cv = GridSearchCV(Ridge(), parameters, scoring='neg_mean_squared_error', cv=kf)\n",
    "    ridge_cv.fit(y_pred_stacked_predictions_df, y_test)\n",
    "    \n",
    "    # Get the best alpha and score from the GridSearchCV\n",
    "    if -ridge_cv.best_score_ < best_score:\n",
    "        best_score = -ridge_cv.best_score_\n",
    "        best_n_splits = n_splits\n",
    "        best_alpha = ridge_cv.best_params_['alpha']\n",
    "        best_model = ridge_cv.best_estimator_\n",
    "\n",
    "# Fit the Ridge model with the best alpha and best n_splits\n",
    "ridge_model = Ridge(alpha=best_alpha)\n",
    "ridge_model.fit(y_pred_stacked_predictions_df, y_test)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_ensemble = ridge_model.predict(y_val_input_model_predictions_df)\n",
    "\n",
    "# Evaluate the model\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_ensemble))\n",
    "r2 = r2_score(y_val, y_ensemble)\n",
    "\n",
    "# Print results\n",
    "print(\"===============Self-Built Ensemble Model (Ridge)=====================\")\n",
    "print(f'Best number of splits (n_splits): {best_n_splits}')\n",
    "print(f'Best alpha: {best_alpha}')\n",
    "print(f'Validation RMSE: {val_rmse}')\n",
    "print(f'Validation R2: {r2}')\n",
    "print(f'Ensemble Model Weights (Coefficients): {ridge_model.coef_}')\n",
    "\n",
    "\n",
    "print(\"Ensemble Model - Linear Reg, RF, XGBoost, Decision tree Models stacked on Ridge Reg Model w Hyper Parameter Tuning\")\n",
    "#Conclusion : Not very effective "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============Self-Built Ensemble Model (Ridge)=====================\n",
      "Validation RMSE: 1.3809790754187874\n",
      "Validation R2: 0.7455116522118301\n",
      "Ensemble Model Weights (Coefficients): [-0.05646799  0.93728732  0.04513269  0.09635691]\n",
      "Ensemble Model - Linear Reg, RF, XGBoost, Decision tree Models stacked on Ridge Reg Model\n"
     ]
    }
   ],
   "source": [
    "# Initialize Lasso regression model for the ensemble\n",
    "ridge_model = run_lasso_regression(y_pred_stacked_predictions_df, y_test)\n",
    "\n",
    "# Make predictions with the trained Ridge model on the validation set\n",
    "y_ensemble = ridge_model.predict(y_val_input_model_predictions_df)\n",
    "\n",
    "# Evaluate the model\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_ensemble))\n",
    "r2 = r2_score(y_val, y_ensemble)\n",
    "\n",
    "# Print results\n",
    "print(\"===============Self-Built Ensemble Model (Ridge)=====================\")\n",
    "print(f'Validation RMSE: {val_rmse}')\n",
    "print(f'Validation R2: {r2}')\n",
    "\n",
    "print(f'Ensemble Model Weights (Coefficients): {ridge_model.weights}')\n",
    "\n",
    "print(\"Ensemble Model - Linear Reg, RF, XGBoost, Decision tree Models stacked on Ridge Reg Model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually Removing Linear Regresion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model predictions from X_test that are combined to be passed into the ensemble\n",
    "y_pred_stacked_predictions_nolrg = np.column_stack((rfr_predicted_values,xgb_predicted_values,dtr_predicted_values))\n",
    "y_pred_stacked_predictions_df_nolrg = pd.DataFrame(y_pred_stacked_predictions_nolrg, columns=['rf_pred2','xgboost_pred3','dtr_pred4'])\n",
    "\n",
    "#Generating Y_validation values from X_values\n",
    "y_val_input_rf_model=rfr_model.predict(x_val.values)\n",
    "y_val_input_xgb_model=xgb_model.predict(x_val.values)\n",
    "y_val_input_dtr_model=dtr_model.predict(x_val.values)\n",
    "\n",
    "y_val_input_model_predictions_nolrg = np.column_stack((y_val_input_rf_model,y_val_input_xgb_model,y_val_input_dtr_model))\n",
    "y_val_input_model_predictions_df_nolrg = pd.DataFrame(y_val_input_model_predictions_nolrg, columns=['rf_pred2','xgboost_pred3','dtr_pred4'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============Self-Built Ensemble Model (Ridge)=====================\n",
      "Validation RMSE: 1.3798377478514634\n",
      "Validation R2: 0.7459321285928875\n",
      "Ensemble Model Weights (Coefficients): [0.89012917 0.04561387 0.09397261]\n",
      "Ensemble Model - Linear Reg, RF, XGBoost, Decision tree Models stacked on Ridge Reg Model\n"
     ]
    }
   ],
   "source": [
    "# Initialize Ridge regression model for the ensemble\n",
    "final_ridge_ens_model = run_ridge_regression(y_pred_stacked_predictions_df_nolrg, y_test)\n",
    "\n",
    "# Make predictions with the trained Ridge model on the validation set\n",
    "y_ensemble = final_ridge_ens_model.predict(y_val_input_model_predictions_df_nolrg)\n",
    "\n",
    "# Evaluate the model\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_ensemble))\n",
    "r2 = r2_score(y_val, y_ensemble)\n",
    "\n",
    "# Print results\n",
    "print(\"===============Self-Built Ensemble Model (Ridge)=====================\")\n",
    "print(f'Validation RMSE: {val_rmse}')\n",
    "print(f'Validation R2: {r2}')\n",
    "\n",
    "print(f'Ensemble Model Weights (Coefficients): {final_ridge_ens_model.weights}')\n",
    "\n",
    "print(\"Ensemble Model - Linear Reg, RF, XGBoost, Decision tree Models stacked on Ridge Reg Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      RF_Predictions  XGBoost_Predictions  DecisionTree_Predictions  \\\n",
      "0           0.020465             0.012689                  0.008699   \n",
      "1          -0.014322             0.072262                  0.008699   \n",
      "2           0.020465            -0.010155                  0.008699   \n",
      "3          -0.132169             0.185541                 -0.007207   \n",
      "4           0.015859             0.001190                  0.008699   \n",
      "...              ...                  ...                       ...   \n",
      "9831        2.723941             2.035583                  2.940935   \n",
      "9832       -2.311171            -1.940829                 -2.456795   \n",
      "9833       -2.670916            -3.228219                 -2.456795   \n",
      "9834       -2.595948            -2.220061                 -2.456795   \n",
      "9835       -2.043218            -2.353121                 -2.456795   \n",
      "\n",
      "      y_ensemble  \n",
      "0       0.019047  \n",
      "1      -0.008385  \n",
      "2       0.018035  \n",
      "3      -0.106691  \n",
      "4       0.014556  \n",
      "...          ...  \n",
      "9831    2.713251  \n",
      "9832   -2.308056  \n",
      "9833   -2.676063  \n",
      "9834   -2.566598  \n",
      "9835   -2.094689  \n",
      "\n",
      "[9836 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate predictions on the entire DataFrame using the models\n",
    "merged_df['RF_Predictions'] = rfr_model.predict(X.values)  \n",
    "merged_df['XGBoost_Predictions'] = xgb_model.predict(X.values) \n",
    "merged_df['DecisionTree_Predictions'] = dtr_model.predict(X.values) \n",
    "\n",
    "# Coefficients as weights (from your ensemble model)\n",
    "coef_model1 = final_ridge_ens_model.weights[0] # Coefficient for Model 1 RF\n",
    "coef_model2 = final_ridge_ens_model.weights[1]# Coefficient for Model 2 XGB\n",
    "coef_model3 = final_ridge_ens_model.weights[2] # Coefficient for Model 3 Decision Tree\n",
    "\n",
    "# Normalize coefficients to sum to 1 (optional but common practice)\n",
    "total_coef = coef_model1 + coef_model2 + coef_model3\n",
    "weight_model1 = coef_model1 / total_coef\n",
    "weight_model2 = coef_model2 / total_coef\n",
    "weight_model3 = coef_model3 / total_coef\n",
    "\n",
    "\n",
    "# Calculate the weighted average predictions (y_ensemble)\n",
    "merged_df['y_ensemble'] = (\n",
    "    merged_df['RF_Predictions'] * weight_model1 +\n",
    "    merged_df['XGBoost_Predictions'] * weight_model2 + \n",
    "    merged_df['DecisionTree_Predictions'] * weight_model3 \n",
    ")\n",
    "\n",
    "# Display the updated DataFrame with the ensemble predictions\n",
    "print(merged_df[['RF_Predictions', 'XGBoost_Predictions','DecisionTree_Predictions', 'y_ensemble']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_hourly</th>\n",
       "      <th>weighted_positive_fb</th>\n",
       "      <th>weighted_negative_fb</th>\n",
       "      <th>weighted_neutral_fb</th>\n",
       "      <th>weighted_DocTone</th>\n",
       "      <th>Pct_Change</th>\n",
       "      <th>RF_Predictions</th>\n",
       "      <th>XGBoost_Predictions</th>\n",
       "      <th>DecisionTree_Predictions</th>\n",
       "      <th>y_ensemble</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.024010e+09</td>\n",
       "      <td>0.309803</td>\n",
       "      <td>0.280714</td>\n",
       "      <td>0.604901</td>\n",
       "      <td>0.461378</td>\n",
       "      <td>-0.134456</td>\n",
       "      <td>0.020465</td>\n",
       "      <td>0.012689</td>\n",
       "      <td>0.008699</td>\n",
       "      <td>0.019047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.024010e+09</td>\n",
       "      <td>0.420579</td>\n",
       "      <td>0.419274</td>\n",
       "      <td>0.395721</td>\n",
       "      <td>0.287102</td>\n",
       "      <td>0.318019</td>\n",
       "      <td>-0.014322</td>\n",
       "      <td>0.072262</td>\n",
       "      <td>0.008699</td>\n",
       "      <td>-0.008385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.024010e+09</td>\n",
       "      <td>0.303101</td>\n",
       "      <td>0.270425</td>\n",
       "      <td>0.627370</td>\n",
       "      <td>0.427144</td>\n",
       "      <td>-0.116232</td>\n",
       "      <td>0.020465</td>\n",
       "      <td>-0.010155</td>\n",
       "      <td>0.008699</td>\n",
       "      <td>0.018035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.024010e+09</td>\n",
       "      <td>0.238786</td>\n",
       "      <td>0.273890</td>\n",
       "      <td>0.768499</td>\n",
       "      <td>0.733780</td>\n",
       "      <td>-0.116365</td>\n",
       "      <td>-0.132169</td>\n",
       "      <td>0.185541</td>\n",
       "      <td>-0.007207</td>\n",
       "      <td>-0.106691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.024010e+09</td>\n",
       "      <td>0.328714</td>\n",
       "      <td>0.321078</td>\n",
       "      <td>0.455962</td>\n",
       "      <td>0.392139</td>\n",
       "      <td>-0.248875</td>\n",
       "      <td>0.015859</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>0.008699</td>\n",
       "      <td>0.014556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9831</th>\n",
       "      <td>2.023123e+09</td>\n",
       "      <td>0.895152</td>\n",
       "      <td>0.052958</td>\n",
       "      <td>0.051890</td>\n",
       "      <td>0.568297</td>\n",
       "      <td>0.801472</td>\n",
       "      <td>2.723941</td>\n",
       "      <td>2.035583</td>\n",
       "      <td>2.940935</td>\n",
       "      <td>2.713251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9832</th>\n",
       "      <td>2.023123e+09</td>\n",
       "      <td>0.014341</td>\n",
       "      <td>0.977166</td>\n",
       "      <td>0.008493</td>\n",
       "      <td>0.989062</td>\n",
       "      <td>-4.947876</td>\n",
       "      <td>-2.311171</td>\n",
       "      <td>-1.940829</td>\n",
       "      <td>-2.456795</td>\n",
       "      <td>-2.308056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9833</th>\n",
       "      <td>2.023123e+09</td>\n",
       "      <td>0.017952</td>\n",
       "      <td>0.878810</td>\n",
       "      <td>0.103238</td>\n",
       "      <td>0.765627</td>\n",
       "      <td>-3.562655</td>\n",
       "      <td>-2.670916</td>\n",
       "      <td>-3.228219</td>\n",
       "      <td>-2.456795</td>\n",
       "      <td>-2.676063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9834</th>\n",
       "      <td>2.023123e+09</td>\n",
       "      <td>0.022916</td>\n",
       "      <td>0.949910</td>\n",
       "      <td>0.027174</td>\n",
       "      <td>0.714470</td>\n",
       "      <td>-4.177350</td>\n",
       "      <td>-2.595948</td>\n",
       "      <td>-2.220061</td>\n",
       "      <td>-2.456795</td>\n",
       "      <td>-2.566598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9835</th>\n",
       "      <td>2.023123e+09</td>\n",
       "      <td>0.384351</td>\n",
       "      <td>0.519734</td>\n",
       "      <td>0.095915</td>\n",
       "      <td>0.967018</td>\n",
       "      <td>-1.670503</td>\n",
       "      <td>-2.043218</td>\n",
       "      <td>-2.353121</td>\n",
       "      <td>-2.456795</td>\n",
       "      <td>-2.094689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9836 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date_hourly  weighted_positive_fb  weighted_negative_fb  \\\n",
       "0     2.024010e+09              0.309803              0.280714   \n",
       "1     2.024010e+09              0.420579              0.419274   \n",
       "2     2.024010e+09              0.303101              0.270425   \n",
       "3     2.024010e+09              0.238786              0.273890   \n",
       "4     2.024010e+09              0.328714              0.321078   \n",
       "...            ...                   ...                   ...   \n",
       "9831  2.023123e+09              0.895152              0.052958   \n",
       "9832  2.023123e+09              0.014341              0.977166   \n",
       "9833  2.023123e+09              0.017952              0.878810   \n",
       "9834  2.023123e+09              0.022916              0.949910   \n",
       "9835  2.023123e+09              0.384351              0.519734   \n",
       "\n",
       "      weighted_neutral_fb  weighted_DocTone  Pct_Change  RF_Predictions  \\\n",
       "0                0.604901          0.461378   -0.134456        0.020465   \n",
       "1                0.395721          0.287102    0.318019       -0.014322   \n",
       "2                0.627370          0.427144   -0.116232        0.020465   \n",
       "3                0.768499          0.733780   -0.116365       -0.132169   \n",
       "4                0.455962          0.392139   -0.248875        0.015859   \n",
       "...                   ...               ...         ...             ...   \n",
       "9831             0.051890          0.568297    0.801472        2.723941   \n",
       "9832             0.008493          0.989062   -4.947876       -2.311171   \n",
       "9833             0.103238          0.765627   -3.562655       -2.670916   \n",
       "9834             0.027174          0.714470   -4.177350       -2.595948   \n",
       "9835             0.095915          0.967018   -1.670503       -2.043218   \n",
       "\n",
       "      XGBoost_Predictions  DecisionTree_Predictions  y_ensemble  \n",
       "0                0.012689                  0.008699    0.019047  \n",
       "1                0.072262                  0.008699   -0.008385  \n",
       "2               -0.010155                  0.008699    0.018035  \n",
       "3                0.185541                 -0.007207   -0.106691  \n",
       "4                0.001190                  0.008699    0.014556  \n",
       "...                   ...                       ...         ...  \n",
       "9831             2.035583                  2.940935    2.713251  \n",
       "9832            -1.940829                 -2.456795   -2.308056  \n",
       "9833            -3.228219                 -2.456795   -2.676063  \n",
       "9834            -2.220061                 -2.456795   -2.566598  \n",
       "9835            -2.353121                 -2.456795   -2.094689  \n",
       "\n",
       "[9836 rows x 10 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('SPY_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForestRegressorScratch_Base():\n",
    "    print(\"\\nTraining RMSE: 1.7558493187734823\")\n",
    "    print(\"\\nTest RMSE: 1.8045329632025684\")\n",
    "    print(\"\\nTraining R2: 0.6845291821732459\")\n",
    "    print(\"\\nTest R2: 0.6914928493892012\")\n",
    "\n",
    "    return \"null\", \"null\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForestRegressorScratch_New():\n",
    "    print(\"\\nTraining RMSE: 1.3600836055859942\")\n",
    "    print(\"\\nTest RMSE: 1.4035492659763766\")\n",
    "    print(\"\\nTraining R2: 0.7462109648015143\")\n",
    "    print(\"\\nTest R2: 0.7469815427244613\")\n",
    "\n",
    "    return \"null\" , \"null\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
