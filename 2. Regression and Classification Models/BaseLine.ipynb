{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline models - consisting of Linear Regression, RFRegressor, XGBoostRegressor fed into a linear regression ensemble. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error,r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "import xgboost as xg \n",
    "import DecisionTreeRegressor as dtg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news = pd.read_csv('/Users/oryining/Documents/NUS MComp/Semester 2/CS5344 - Big Data Analytics Technology/CS5344_Project/1. Data Retrieval and Processing of News and Stock Prices/final_sample_finbert.csv')\n",
    "columns_to_select = ['Date_hourly', 'weighted_positive_fb', 'weighted_negative_fb', 'weighted_neutral_fb','weighted_DocTone']\n",
    "df_news = df_news[columns_to_select]\n",
    "df_news['Date_hourly'] = df_news['Date_hourly'].astype(str).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stock_price = pd.read_csv('/Users/oryining/Documents/NUS MComp/Semester 2/CS5344 - Big Data Analytics Technology/CS5344_Project/1. Data Retrieval and Processing of News and Stock Prices/us_2024_ticker combined versions/SPY_Combined_WithPriceChange.csv',index_col=0)\n",
    "df_stock_price\n",
    "df_stock_price['Date'] = df_stock_price['Date'].astype(str)\n",
    "df_stock_price['Time'] = df_stock_price['Time'].astype(str).str.zfill(6)\n",
    "\n",
    "df_stock_price['Date_hourly'] = '20' + df_stock_price['Date'] + df_stock_price['Time'].str[:2]\n",
    "df_stock_price=df_stock_price.iloc[:, -2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_news' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Merge the datasets on the 'Date_hourly' column using an inner join to keep only matching rows\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(\u001b[43mdf_news\u001b[49m, df_stock_price, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate_hourly\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m merged_df\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted_negative_fb\u001b[39m\u001b[38;5;124m\"\u001b[39m,ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_news' is not defined"
     ]
    }
   ],
   "source": [
    "# Merge the datasets on the 'Date_hourly' column using an inner join to keep only matching rows\n",
    "merged_df = pd.merge(df_news, df_stock_price, on='Date_hourly', how='inner')\n",
    "merged_df.sort_values(\"weighted_negative_fb\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train Test Split and creating of x_train, x_val, x and y_train, y_val, y_test\n",
    "# Y = merged_df[['PriceChange']]  \n",
    "# X = merged_df[['weighted_positive_fb', 'weighted_negative_fb', 'weighted_neutral_fb','weighted_DocTone']]  \n",
    "# x_train_val, x_test, y_train_val, y_test = train_test_split(X, Y, test_size=0.2, random_state=1010)\n",
    "# x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.25, random_state=1010)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv('/Users/oryining/Documents/NUS MComp/Semester 2/CS5344 - Big Data Analytics Technology/CS5344_Project/1. Data Retrieval and Processing of News and Stock Prices/final_dataset.csv',index_col=0)\n",
    "\n",
    "# Train Test Split and creating of x_train, x_val, x and y_train, y_val, y_test\n",
    "Y = merged_df[['Pct_Change']]  \n",
    "X = merged_df[['weighted_positive_fb', 'weighted_negative_fb', 'weighted_neutral_fb','weighted_DocTone']]  \n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(X, Y, test_size=0.2, random_state=1616)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.25, random_state=1616)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression in baseline form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearRegressionBaseLine(x_train,x_test,y_train,y_test):\n",
    "    \n",
    "    #Building model with Train data\n",
    "    reg_model= LinearRegression().fit(x_train, y_train)\n",
    "    y_pred = reg_model.predict(x_test)\n",
    "    val_rmse_reg_model = root_mean_squared_error(y_test, y_pred)\n",
    "    r2_reg_model = r2_score(y_test,y_pred)\n",
    "    \n",
    "    print(f'Test RMSE: {val_rmse_reg_model}')\n",
    "    print(f'Test R2: {r2_reg_model}')\n",
    "\n",
    "    print(\"Model details are coefficients of \"+str(reg_model.coef_)+\" intercept of \"+str(reg_model.intercept_))\n",
    "\n",
    "    return y_pred,reg_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.648817326439581\n",
      "Test R2: 0.6508259456420558\n",
      "Model details are coefficients of [[ 4.22366227 -2.62350391  0.80944256 -0.11299289]] intercept of [-0.71761997]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-1.5039925 ],\n",
       "        [ 1.00041905],\n",
       "        [-1.59979466],\n",
       "        ...,\n",
       "        [-2.03336589],\n",
       "        [ 2.84563284],\n",
       "        [-2.17758208]]),\n",
       " LinearRegression())"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinearRegressionBaseLine(x_train,x_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Regressor in baseline form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Incoporating K Fold Cross Validation to Further Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForestRegressorBaseline(x_train,x_test,y_train,y_test):\n",
    "    \n",
    "    rf_model = RandomForestRegressor(random_state=30)\n",
    "    rf_model.fit(x_train, y_train.values.ravel())\n",
    "    y_pred = rf_model.predict(x_test)\n",
    "    val_rmse = root_mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f'Test RMSE: {val_rmse}')\n",
    "    print(f'Test R2: {r2}')\n",
    "\n",
    "    return y_pred,rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.4604754895799814\n",
      "Test R2: 0.7260410921341554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-2.52151805,  2.66661032, -3.18558855, ..., -1.81774796,\n",
       "         2.54803464, -2.54003689]),\n",
       " RandomForestRegressor(random_state=30))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestRegressorBaseline(x_train,x_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost Regressor in baseline form "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGBoostRegressorBaseline(x_train,x_test,y_train,y_test):\n",
    "    \n",
    "    xgb_model = xg.XGBRegressor(random_state=42)\n",
    "    xgb_model.fit(x_train, y_train.values.ravel())\n",
    "    y_pred = xgb_model.predict(x_test)\n",
    "    val_rmse = root_mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f'Test RMSE: {val_rmse}')\n",
    "    print(f'Test R2: {r2}')\n",
    "\n",
    "    return y_pred,xgb_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Baseline Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "def DecisionTreeRegressorBaseline(x_train, x_test, y_train, y_test):\n",
    "    # Ensure y_train and y_test are 1D arrays for compatibility\n",
    "    y_train = np.ravel(y_train)  # Converts y_train to a 1D array if it isn't already\n",
    "    y_test = np.ravel(y_test)    # Converts y_test to a 1D array if it isn't already\n",
    "\n",
    "    # Initialize and fit the model\n",
    "    dt_model = DecisionTreeRegressor()\n",
    "    dt_model.fit(x_train, y_train)\n",
    "\n",
    "    # Make predictions on test data\n",
    "    y_pred_test = dt_model.predict(x_test)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    test_r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "    # Make predictions on training data\n",
    "    y_pred_train = dt_model.predict(x_train)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    train_r2 = r2_score(y_train, y_pred_train)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f'Test RMSE: {test_rmse}')\n",
    "    print(f'Test R2: {test_r2}')\n",
    "    print(f'Train RMSE: {train_rmse}')\n",
    "    print(f'Train R2: {train_r2}')\n",
    "\n",
    "    return y_pred_test, dt_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.9192529069482223\n",
      "Test R2: 0.5268909074373522\n",
      "Train RMSE: 0.0\n",
      "Train R2: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-1.43178846,  2.44032979, -3.20240389, ..., -0.1550891 ,\n",
       "         3.53855464, -0.99602472]),\n",
       " DecisionTreeRegressor())"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTreeRegressorBaseline(x_train,x_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble model taking in variables from 3 individual models to combine outputs into a linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EnsembleBaseLine():\n",
    "\n",
    "    #This section calls the initial models to return a series of predictions\n",
    "    print(\"\\n\")\n",
    "    print(\"===============Linear Regresion BaseLine Outputs=====================\")\n",
    "    y_pred_linear_regression_input, input_reg_model= LinearRegressionBaseLine(x_train,x_test,y_train,y_test)\n",
    "    print(\"===============RandomForest Regressor Baseline Outputs================\")\n",
    "    y_pred_random_forest_regressor,input_rf_model = RandomForestRegressorBaseline(x_train,x_test,y_train,y_test)\n",
    "    print(\"===============XGBoost Regressor Baseline Outputs================\")\n",
    "    y_pred_xgb_regressor,input_xgb_model = XGBoostRegressorBaseline(x_train,x_test,y_train,y_test)\n",
    "    print(\"===============Decision Tree Regressor Baseline Outputs================\")\n",
    "    y_pred_dt_regressor,input_dt_model = DecisionTreeRegressorBaseline(x_train,x_test,y_train,y_test)\n",
    "\n",
    "    #Model predictions are combined to be passed into the ensemble\n",
    "    y_pred_stacked_predictions = np.column_stack((y_pred_linear_regression_input, y_pred_random_forest_regressor,y_pred_xgb_regressor,y_pred_dt_regressor))\n",
    "    y_pred_stacked_predictions_df = pd.DataFrame(y_pred_stacked_predictions, columns=['reg_pred1', 'rf_pred2','xgboost_pred3','dt_pred4'])\n",
    "\n",
    "    #Processing of data to be passed in as ensemble prediction using x_val \n",
    "    y_val_input_reg_model = input_reg_model.predict(x_val)\n",
    "    y_val_input_rf_model = input_rf_model.predict(x_val)\n",
    "    y_val_input_xgb_model = input_xgb_model.predict(x_val)\n",
    "    y_val_input_dt_model = input_dt_model.predict(x_val)\n",
    "\n",
    "    y_val_input_model_predictions = np.column_stack((y_val_input_reg_model, y_val_input_rf_model,y_val_input_xgb_model, y_val_input_dt_model))\n",
    "    y_val_input_model_predictions_df = pd.DataFrame(y_val_input_model_predictions, columns=['reg_pred1', 'rf_pred2','xgboost_pred3','dt_pred4'])\n",
    "    \n",
    "    \n",
    "    #Ensemble Model \n",
    "    print(\"\\n\")\n",
    "    print(\"===============Ensemble Baseline Model============================\")\n",
    "    ensemble_model= LinearRegression().fit(y_pred_stacked_predictions_df,y_test) # Predicted Values of the Models, and y_test is the Y variable\n",
    "    y_ensemble = ensemble_model.predict(y_val_input_model_predictions_df) \n",
    "\n",
    "    val_rmse = root_mean_squared_error(y_ensemble, y_val)\n",
    "    r2 = r2_score(y_ensemble, y_val)\n",
    "    print(f'Validation RMSE: {val_rmse}')\n",
    "    print(f'Validation R2: {r2}')\n",
    "\n",
    "    print(\"Model details are coefficients of \"+str(ensemble_model.coef_)+\" intercept of \"+str(ensemble_model.intercept_))\n",
    "\n",
    "    # print(y_ensemble)\n",
    "    # print(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "===============Linear Regresion BaseLine Outputs=====================\n",
      "Test RMSE: 1.648817326439581\n",
      "Test R2: 0.6508259456420558\n",
      "Model details are coefficients of [[ 4.22366227 -2.62350391  0.80944256 -0.11299289]] intercept of [-0.71761997]\n",
      "===============RandomForest Regressor Baseline Outputs================\n",
      "Test RMSE: 1.4604754895799814\n",
      "Test R2: 0.7260410921341554\n",
      "===============XGBoost Regressor Baseline Outputs================\n",
      "Test RMSE: 1.5011383343942033\n",
      "Test R2: 0.7105734944343567\n",
      "===============Decision Tree Regressor Baseline Outputs================\n",
      "Test RMSE: 1.939963171522729\n",
      "Test R2: 0.5166253716076841\n",
      "\n",
      "\n",
      "===============Ensemble Baseline Model============================\n",
      "Validation RMSE: 1.4069870815370709\n",
      "Validation R2: 0.6486742363384139\n",
      "Model details are coefficients of [[1.85856476e-01 6.29047600e-01 2.17854312e-01 3.03612031e-04]] intercept of [-0.02242535]\n"
     ]
    }
   ],
   "source": [
    "EnsembleBaseLine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
