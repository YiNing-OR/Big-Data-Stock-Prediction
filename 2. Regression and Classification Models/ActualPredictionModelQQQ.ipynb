{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from LinearRegression import run_linear_regression\n",
    "from RandomForestRegressor_New import RandomForestRegressor\n",
    "from RandomForestRegressor import RandomForestRegressor_Base\n",
    "from XGBoostRegressor import XGBoostRegressor \n",
    "from DecisionTreeRegressor import DecisionTreeRegressor\n",
    "import numpy as np\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from RidgeLinearRegression import run_ridge_regression\n",
    "from LassoLinearRegression import run_lasso_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv('/Users/oryining/Documents/NUS MComp/Semester 2/CS5344 - Big Data Analytics Technology/CS5344_Project/1. Data Retrieval and Processing of News and Stock Prices/QQQ_Sentiments_PriceChange.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split and creating of x_train, x_val, x and y_train, y_val, y_test\n",
    "Y = merged_df[['PriceChange']]  \n",
    "X = merged_df[['weighted_positive_fb', 'weighted_negative_fb', 'weighted_neutral_fb','weighted_DocTone']]  \n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(X, Y, test_size=0.2, random_state=1616)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.25, random_state=1616)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Models to input to Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearRegressionScratch():\n",
    "    #Linear Regresion Model\n",
    "    lin_reg_model = run_linear_regression(x_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    lin_reg_predicted_values = lin_reg_model.predict(x_test.values)\n",
    "\n",
    "    train_score = lin_reg_model.score(x_train.values, y_train.values.ravel())\n",
    "    test_score = lin_reg_model.score(x_test.values, y_test.values.ravel())\n",
    "    train_rmse = lin_reg_model.rmse(x_train.values, y_train.values.ravel())\n",
    "    test_rmse = lin_reg_model.rmse(x_test.values, y_test.values.ravel())\n",
    "\n",
    "    print(f\"Training RMSE: {train_rmse}\")\n",
    "    print(f\"Test RMSE: {test_rmse}\")\n",
    "\n",
    "    print(f\"Training R2: {train_score}\")\n",
    "    print(f\"Test R2: {test_score}\")\n",
    "\n",
    "\n",
    "    return lin_reg_predicted_values,lin_reg_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RidgeRegressionScratch():\n",
    "    #Ridge Regresion Model\n",
    "    rig_reg_model = run_ridge_regression(x_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    rig_reg_predicted_values = rig_reg_model.predict(x_test.values)\n",
    "\n",
    "    train_score = rig_reg_model.score(x_train.values, y_train.values.ravel())\n",
    "    test_score = rig_reg_model.score(x_test.values, y_test.values.ravel())\n",
    "    train_rmse = rig_reg_model.rmse(x_train.values, y_train.values.ravel())\n",
    "    test_rmse = rig_reg_model.rmse(x_test.values, y_test.values.ravel())\n",
    "\n",
    "    print(f\"Training RMSE: {train_rmse}\")\n",
    "    print(f\"Test RMSE: {test_rmse}\")\n",
    "\n",
    "    print(f\"Training R2: {train_score}\")\n",
    "    print(f\"Test R2: {test_score}\")\n",
    "\n",
    "\n",
    "    return rig_reg_predicted_values,rig_reg_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Regressor \n",
    "def RandomForestRegressorScratch_New():\n",
    "\n",
    "    rfr_model = RandomForestRegressor(n_estimators=5, max_depth=5, min_samples_split=8)\n",
    "    rfr_model.fit(x_train.values, y_train.values.ravel())\n",
    "    rfr_predicted_values = rfr_model.predict(x_test.values)\n",
    "\n",
    "    train_score = rfr_model.score(x_train.values, y_train.values.ravel())\n",
    "    test_score = rfr_model.score(x_test.values, y_test.values.ravel())\n",
    "    train_rmse = rfr_model.rmse(x_train.values, y_train.values.ravel())\n",
    "    test_rmse = rfr_model.rmse(x_test.values, y_test.values.ravel())\n",
    "\n",
    "    print(f\"Training RMSE: {train_rmse}\")\n",
    "    print(f\"Test RMSE: {test_rmse}\")\n",
    "\n",
    "\n",
    "    print(f\"Training R2: {train_score}\")\n",
    "    print(f\"Test R2: {test_score}\")\n",
    "\n",
    "    return rfr_predicted_values,rfr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Regressor \n",
    "def RandomForestRegressorScratch_Base():\n",
    "\n",
    "    rfr_model = RandomForestRegressor_Base(n_estimators=5, max_depth=5, min_samples_split=8)\n",
    "    rfr_model.fit(x_train.values, y_train.values.ravel())\n",
    "    rfr_predicted_values = rfr_model.predict(x_test.values)\n",
    "\n",
    "    train_score = rfr_model.score(x_train.values, y_train.values.ravel())\n",
    "    test_score = rfr_model.score(x_test.values, y_test.values.ravel())\n",
    "    train_rmse = rfr_model.rmse(x_train.values, y_train.values.ravel())\n",
    "    test_rmse = rfr_model.rmse(x_test.values, y_test.values.ravel())\n",
    "\n",
    "    print(f\"Training RMSE: {train_rmse}\")\n",
    "    print(f\"Test RMSE: {test_rmse}\")\n",
    "\n",
    "\n",
    "    print(f\"Training R2: {train_score}\")\n",
    "    print(f\"Test R2: {test_score}\")\n",
    "\n",
    "    return rfr_predicted_values,rfr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBOOST\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate evaluation metrics\n",
    "def evaluate_metrics(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    \n",
    "    return {\n",
    "        \"Mean Absolute Error (MAE)\": mae,\n",
    "        \"Mean Squared Error (MSE)\": mse,\n",
    "        \"Root Mean Squared Error (RMSE)\": rmse,\n",
    "        \"R-Squared (R2)\": r2\n",
    "    }\n",
    "\n",
    "# Main XGBoost Regressor function with feature engineering and extended evaluation\n",
    "def XGBoostRegressorScratch():\n",
    "    # Apply feature engineering on training and test data\n",
    "\n",
    "    # Initialize the model with regularization parameters\n",
    "    xgb_model = XGBoostRegressor(n_estimators=100, learning_rate=0.2, max_depth=8)\n",
    "    xgb_model.fit(x_train.values, y_train.values.ravel())\n",
    "\n",
    "    # Predictions on the test set\n",
    "    xgb_predicted_values = xgb_model.predict(x_test.values)\n",
    "\n",
    "    # Calculate training metrics\n",
    "    train_metrics = evaluate_metrics(xgb_model, x_train.values, y_train.values.ravel())\n",
    "    test_metrics = evaluate_metrics(xgb_model, x_test.values, y_test.values.ravel())\n",
    "\n",
    "    # Print training metrics\n",
    "    print(\"Training Metrics:\")\n",
    "    for metric, value in train_metrics.items():\n",
    "        print(f\"{metric}: {value}\")\n",
    "\n",
    "    # Print test metrics\n",
    "    print(\"\\nTest Metrics:\")\n",
    "    for metric, value in test_metrics.items():\n",
    "        print(f\"{metric}: {value}\")\n",
    "\n",
    "    return xgb_predicted_values, xgb_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Regressor\n",
    "def DecisionTreeScratch_New():\n",
    "\n",
    "    dtr_model = DecisionTreeRegressor(max_depth=5,min_samples_split=2, min_samples_leaf=1, max_features=1, min_impurity_decrease=0.0)\n",
    "    dtr_model.fit(x_train.values, y_train.values.ravel())\n",
    "    dtr_predicted_values = dtr_model.predict(x_test.values)\n",
    "\n",
    "    train_score = dtr_model.score(x_train.values, y_train.values.ravel())\n",
    "    test_score = dtr_model.score(x_test.values, y_test.values.ravel())\n",
    "    train_rmse = dtr_model.rmse(x_train.values, y_train.values.ravel())\n",
    "    test_rmse = dtr_model.rmse(x_test.values, y_test.values.ravel())\n",
    "\n",
    "    print(f\"Training RMSE: {train_rmse}\")\n",
    "    print(f\"Test RMSE: {test_rmse}\")\n",
    "\n",
    "\n",
    "    print(f\"Training R2: {train_score}\")\n",
    "    print(f\"Test R2: {test_score}\")\n",
    "\n",
    "    return dtr_predicted_values,dtr_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============Self-Built Linear Regresion Outputs=====================\n",
      "Training RMSE: 0.6614085893317407\n",
      "Test RMSE: 0.6465684858838927\n",
      "Training R2: 0.638396214142319\n",
      "Test R2: 0.6539966500308794\n"
     ]
    }
   ],
   "source": [
    "print(\"===============Self-Built Linear Regresion Outputs=====================\")\n",
    "lin_reg_predicted_values, lin_reg_model= LinearRegressionScratch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============Self-Built Linear Regresion Outputs=====================\n",
      "Training RMSE: 0.6614144997300694\n",
      "Test RMSE: 0.6466606771610861\n",
      "Training R2: 0.6383897514746268\n",
      "Test R2: 0.653897972889713\n"
     ]
    }
   ],
   "source": [
    "print(\"===============Self-Built Linear Regresion Outputs=====================\")\n",
    "rig_reg_predicted_values,rig_reg_model = RidgeRegressionScratch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============Decision Tree Regresion Outputs=====================\n",
      "Training RMSE: 0.5769048546307943\n",
      "Test RMSE: 0.5732548796306146\n",
      "Training R2: 0.7248929659671497\n",
      "Test R2: 0.7280138698151888\n"
     ]
    }
   ],
   "source": [
    "print(\"===============Decision Tree Regresion Outputs=====================\")\n",
    "dtr_predicted_values,dtr_model= DecisionTreeScratch_New()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============Self-Built RandomForest Regressor Outputs================\n",
      "Training RMSE: 0.5622126864581874\n",
      "Test RMSE: 0.5589620606907584\n",
      "Training R2: 0.7387269649048813\n",
      "Test R2: 0.7414075146456767\n"
     ]
    }
   ],
   "source": [
    "print(\"===============Self-Built RandomForest Regressor Outputs================\")\n",
    "rfr_predicted_values,rfr_model = RandomForestRegressorScratch_New()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============Self-Built RandomForest Regressor Outputs================\n",
      "Training RMSE: 0.5645986311444033\n",
      "Test RMSE: 0.5605810346123217\n",
      "Training R2: 0.7365046536839617\n",
      "Test R2: 0.7399073742476123\n"
     ]
    }
   ],
   "source": [
    "print(\"===============Self-Built RandomForest Regressor Outputs================\")\n",
    "rfr_predicted_values_base,rfr_model_base = RandomForestRegressorScratch_Base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============Self-Built XGBoost Regressor Baseline Outputs============\n",
      "Training Metrics:\n",
      "Mean Absolute Error (MAE): 0.2517445986950525\n",
      "Mean Squared Error (MSE): 0.0984936285502565\n",
      "Root Mean Squared Error (RMSE): 0.3138369458018869\n",
      "R-Squared (R2): 0.9185855590606258\n",
      "\n",
      "Test Metrics:\n",
      "Mean Absolute Error (MAE): 0.4881659930273053\n",
      "Mean Squared Error (MSE): 0.3401507611054236\n",
      "Root Mean Squared Error (RMSE): 0.5832244517382854\n",
      "R-Squared (R2): 0.7184712937190334\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"===============Self-Built XGBoost Regressor Baseline Outputs============\")\n",
    "xgb_predicted_values,xgb_model = XGBoostRegressorScratch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placing All Models in Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model predictions from X_test that are combined to be passed into the ensemble\n",
    "y_pred_stacked_predictions = np.column_stack((lin_reg_predicted_values, rfr_predicted_values,xgb_predicted_values,dtr_predicted_values))\n",
    "y_pred_stacked_predictions_df = pd.DataFrame(y_pred_stacked_predictions, columns=['reg_pred1', 'rf_pred2','xgboost_pred3','dtr_pred4'])\n",
    "\n",
    "#Generating Y_validation values from X_values\n",
    "y_val_input_reg_model = lin_reg_model.predict(x_val.values)\n",
    "y_val_input_rf_model=rfr_model.predict(x_val.values)\n",
    "y_val_input_xgb_model=xgb_model.predict(x_val.values)\n",
    "y_val_input_dtr_model=dtr_model.predict(x_val.values)\n",
    "\n",
    "y_val_input_model_predictions = np.column_stack((y_val_input_reg_model, y_val_input_rf_model,y_val_input_xgb_model,y_val_input_dtr_model))\n",
    "y_val_input_model_predictions_df = pd.DataFrame(y_val_input_model_predictions, columns=['reg_pred1', 'rf_pred2','xgboost_pred3','dtr_pred4'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============Self-Built Ensemble Model============================\n",
      "Validation RMSE: 0.5760636725300242\n",
      "[0.00190009 0.70690029 0.17850668 0.11744616]\n",
      "Validation R2: 0.6318816576087529\n",
      "Ensemble Model - Linear Reg, RF, XGBoost, Decision tree Models stacked on Linear Reg Model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ensemble_model= run_linear_regression(y_pred_stacked_predictions_df,y_test) # Predicted Values of the Models, and y_test is the Y variable\n",
    "y_ensemble = ensemble_model.predict(y_val_input_model_predictions_df) \n",
    "\n",
    "val_rmse = root_mean_squared_error(y_ensemble, y_val)\n",
    "r2 = r2_score(y_ensemble, y_val)\n",
    "\n",
    "print(\"===============Self-Built Ensemble Model============================\")\n",
    "print(f'Validation RMSE: {val_rmse}')\n",
    "print(ensemble_model.weights)\n",
    "print(f'Validation R2: {r2}')\n",
    "\n",
    "print(\"Ensemble Model - Linear Reg, RF, XGBoost, Decision tree Models stacked on Linear Reg Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============Self-Built Ensemble Model (Ridge)=====================\n",
      "Validation RMSE: 0.576165532270548\n",
      "Validation R2: 0.7230383929597302\n",
      "Ensemble Model Weights (Coefficients): [0.00452361 0.68693093 0.18374981 0.12973316]\n",
      "Ensemble Model - Linear Reg, RF, XGBoost, Decision tree Models stacked on Ridge Reg Model\n"
     ]
    }
   ],
   "source": [
    "# Initialize Ridge regression model for the ensemble\n",
    "ridge_model = run_ridge_regression(y_pred_stacked_predictions_df, y_test)\n",
    "\n",
    "# Make predictions with the trained Ridge model on the validation set\n",
    "y_ensemble = ridge_model.predict(y_val_input_model_predictions_df)\n",
    "\n",
    "# Evaluate the model\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_ensemble))\n",
    "r2 = r2_score(y_val, y_ensemble)\n",
    "\n",
    "# Print results\n",
    "print(\"===============Self-Built Ensemble Model (Ridge)=====================\")\n",
    "print(f'Validation RMSE: {val_rmse}')\n",
    "print(f'Validation R2: {r2}')\n",
    "\n",
    "print(f'Ensemble Model Weights (Coefficients): {ridge_model.weights}')\n",
    "\n",
    "print(\"Ensemble Model - Linear Reg, RF, XGBoost, Decision tree Models stacked on Ridge Reg Model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============Self-Built Ensemble Model (Ridge)=====================\n",
      "Best number of splits (n_splits): 20\n",
      "Best alpha: 1.6\n",
      "Validation RMSE: 0.576226382144485\n",
      "Validation R2: 0.7229798890476712\n",
      "Ensemble Model Weights (Coefficients): [[0.0060324  0.67588564 0.18666189 0.13645731]]\n",
      "Ensemble Model - Linear Reg, RF, XGBoost, Decision tree Models stacked on Ridge Reg Model w Hyper Parameter Tuning\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define parameter grid for alpha\n",
    "parameters = {'alpha': [0.01, 0.1, 1, 1.5, 1.6, 3, 3.01, 3.05, 3.1, 3.5, 5, 10, 100, 100]}\n",
    "\n",
    "# List of n_splits to try\n",
    "n_splits_options = [3, 5, 7, 10, 20, 30]\n",
    "best_score = float(\"inf\")\n",
    "best_n_splits = None\n",
    "best_alpha = None\n",
    "best_model = None\n",
    "\n",
    "# Loop through different values of n_splits\n",
    "for n_splits in n_splits_options:\n",
    "    # Set up KFold with the current number of splits\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Set up GridSearchCV with the current KFold\n",
    "    ridge_cv = GridSearchCV(Ridge(), parameters, scoring='neg_mean_squared_error', cv=kf)\n",
    "    ridge_cv.fit(y_pred_stacked_predictions_df, y_test)\n",
    "    \n",
    "    # Get the best alpha and score from the GridSearchCV\n",
    "    if -ridge_cv.best_score_ < best_score:\n",
    "        best_score = -ridge_cv.best_score_\n",
    "        best_n_splits = n_splits\n",
    "        best_alpha = ridge_cv.best_params_['alpha']\n",
    "        best_model = ridge_cv.best_estimator_\n",
    "\n",
    "# Fit the Ridge model with the best alpha and best n_splits\n",
    "ridge_model = Ridge(alpha=best_alpha)\n",
    "ridge_model.fit(y_pred_stacked_predictions_df, y_test)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_ensemble = ridge_model.predict(y_val_input_model_predictions_df)\n",
    "\n",
    "# Evaluate the model\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_ensemble))\n",
    "r2 = r2_score(y_val, y_ensemble)\n",
    "\n",
    "# Print results\n",
    "print(\"===============Self-Built Ensemble Model (Ridge)=====================\")\n",
    "print(f'Best number of splits (n_splits): {best_n_splits}')\n",
    "print(f'Best alpha: {best_alpha}')\n",
    "print(f'Validation RMSE: {val_rmse}')\n",
    "print(f'Validation R2: {r2}')\n",
    "print(f'Ensemble Model Weights (Coefficients): {ridge_model.coef_}')\n",
    "\n",
    "\n",
    "print(\"Ensemble Model - Linear Reg, RF, XGBoost, Decision tree Models stacked on Ridge Reg Model w Hyper Parameter Tuning\")\n",
    "#Conclusion : Not very effective "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============Self-Built Ensemble Model (Ridge)=====================\n",
      "Validation RMSE: 0.5760521193530256\n",
      "Validation R2: 0.72314741694902\n",
      "Ensemble Model Weights (Coefficients): [0.00122441 0.70865552 0.17867054 0.11583851]\n",
      "Ensemble Model - Linear Reg, RF, XGBoost, Decision tree Models stacked on Ridge Reg Model\n"
     ]
    }
   ],
   "source": [
    "# Initialize Lasso regression model for the ensemble\n",
    "ridge_model = run_lasso_regression(y_pred_stacked_predictions_df, y_test)\n",
    "\n",
    "# Make predictions with the trained Ridge model on the validation set\n",
    "y_ensemble = ridge_model.predict(y_val_input_model_predictions_df)\n",
    "\n",
    "# Evaluate the model\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_ensemble))\n",
    "r2 = r2_score(y_val, y_ensemble)\n",
    "\n",
    "# Print results\n",
    "print(\"===============Self-Built Ensemble Model (Ridge)=====================\")\n",
    "print(f'Validation RMSE: {val_rmse}')\n",
    "print(f'Validation R2: {r2}')\n",
    "\n",
    "print(f'Ensemble Model Weights (Coefficients): {ridge_model.weights}')\n",
    "\n",
    "print(\"Ensemble Model - Linear Reg, RF, XGBoost, Decision tree Models stacked on Ridge Reg Model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually Removing Linear Regresion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model predictions from X_test that are combined to be passed into the ensemble\n",
    "y_pred_stacked_predictions_nolrg = np.column_stack((rfr_predicted_values,xgb_predicted_values,dtr_predicted_values))\n",
    "y_pred_stacked_predictions_df_nolrg = pd.DataFrame(y_pred_stacked_predictions_nolrg, columns=['rf_pred2','xgboost_pred3','dtr_pred4'])\n",
    "\n",
    "#Generating Y_validation values from X_values\n",
    "y_val_input_rf_model=rfr_model.predict(x_val.values)\n",
    "y_val_input_xgb_model=xgb_model.predict(x_val.values)\n",
    "y_val_input_dtr_model=dtr_model.predict(x_val.values)\n",
    "\n",
    "y_val_input_model_predictions_nolrg = np.column_stack((y_val_input_rf_model,y_val_input_xgb_model,y_val_input_dtr_model))\n",
    "y_val_input_model_predictions_df_nolrg = pd.DataFrame(y_val_input_model_predictions_nolrg, columns=['rf_pred2','xgboost_pred3','dtr_pred4'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============Self-Built Ensemble Model (Ridge)=====================\n",
      "Validation RMSE: 0.5761287017304241\n",
      "Validation R2: 0.7230738005604245\n",
      "Ensemble Model Weights (Coefficients): [0.68977076 0.18410519 0.13049853]\n",
      "Ensemble Model - Linear Reg, RF, XGBoost, Decision tree Models stacked on Ridge Reg Model\n"
     ]
    }
   ],
   "source": [
    "# Initialize Ridge regression model for the ensemble\n",
    "final_ridge_ens_model = run_ridge_regression(y_pred_stacked_predictions_df_nolrg, y_test)\n",
    "\n",
    "# Make predictions with the trained Ridge model on the validation set\n",
    "y_ensemble = final_ridge_ens_model.predict(y_val_input_model_predictions_df_nolrg)\n",
    "\n",
    "# Evaluate the model\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_ensemble))\n",
    "r2 = r2_score(y_val, y_ensemble)\n",
    "\n",
    "# Print results\n",
    "print(\"===============Self-Built Ensemble Model (Ridge)=====================\")\n",
    "print(f'Validation RMSE: {val_rmse}')\n",
    "print(f'Validation R2: {r2}')\n",
    "\n",
    "print(f'Ensemble Model Weights (Coefficients): {final_ridge_ens_model.weights}')\n",
    "\n",
    "print(\"Ensemble Model - Linear Reg, RF, XGBoost, Decision tree Models stacked on Ridge Reg Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      RF_Predictions  XGBoost_Predictions  DecisionTree_Predictions  \\\n",
      "0          -0.014183            -0.010086                 -0.019364   \n",
      "1           0.080878             0.071155                 -0.328331   \n",
      "2           0.055349            -0.199494                 -0.019364   \n",
      "3          -0.042440            -0.154335                 -0.019364   \n",
      "4           0.043554            -0.119616                 -0.019364   \n",
      "...              ...                  ...                       ...   \n",
      "9771        0.982934             1.215863                  0.998393   \n",
      "9772        0.845767             0.753560                  0.904055   \n",
      "9773        1.053047             1.382885                  0.998393   \n",
      "9774       -1.007822            -1.474893                 -0.328331   \n",
      "9775        0.982934             0.800876                  0.904055   \n",
      "\n",
      "      y_ensemble  \n",
      "0      -0.014105  \n",
      "1       0.025927  \n",
      "2      -0.001072  \n",
      "3      -0.059952  \n",
      "4       0.005469  \n",
      "...          ...  \n",
      "9771    1.027639  \n",
      "9772    0.836438  \n",
      "9773    1.106406  \n",
      "9774   -1.005151  \n",
      "9775    0.939313  \n",
      "\n",
      "[9776 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate predictions on the entire DataFrame using the models\n",
    "merged_df['RF_Predictions'] = rfr_model.predict(X.values)  \n",
    "merged_df['XGBoost_Predictions'] = xgb_model.predict(X.values) \n",
    "merged_df['DecisionTree_Predictions'] = dtr_model.predict(X.values) \n",
    "\n",
    "# Coefficients as weights (from your ensemble model)\n",
    "coef_model1 = final_ridge_ens_model.weights[0] # Coefficient for Model 1 RF\n",
    "coef_model2 = final_ridge_ens_model.weights[1]# Coefficient for Model 2 XGB\n",
    "coef_model3 = final_ridge_ens_model.weights[2] # Coefficient for Model 3 Decision Tree\n",
    "\n",
    "# Normalize coefficients to sum to 1 (optional but common practice)\n",
    "total_coef = coef_model1 + coef_model2 + coef_model3\n",
    "weight_model1 = coef_model1 / total_coef\n",
    "weight_model2 = coef_model2 / total_coef\n",
    "weight_model3 = coef_model3 / total_coef\n",
    "\n",
    "\n",
    "# Calculate the weighted average predictions (y_ensemble)\n",
    "merged_df['y_ensemble'] = (\n",
    "    merged_df['RF_Predictions'] * weight_model1 +\n",
    "    merged_df['XGBoost_Predictions'] * weight_model2 + \n",
    "    merged_df['DecisionTree_Predictions'] * weight_model3 \n",
    ")\n",
    "\n",
    "# Display the updated DataFrame with the ensemble predictions\n",
    "print(merged_df[['RF_Predictions', 'XGBoost_Predictions','DecisionTree_Predictions', 'y_ensemble']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date_hourly</th>\n",
       "      <th>weighted_positive_fb</th>\n",
       "      <th>weighted_negative_fb</th>\n",
       "      <th>weighted_neutral_fb</th>\n",
       "      <th>weighted_DocTone</th>\n",
       "      <th>PriceChange</th>\n",
       "      <th>RF_Predictions</th>\n",
       "      <th>XGBoost_Predictions</th>\n",
       "      <th>DecisionTree_Predictions</th>\n",
       "      <th>y_ensemble</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2024010210</td>\n",
       "      <td>0.309803</td>\n",
       "      <td>0.280714</td>\n",
       "      <td>0.604901</td>\n",
       "      <td>0.461378</td>\n",
       "      <td>-0.298581</td>\n",
       "      <td>-0.014183</td>\n",
       "      <td>-0.010086</td>\n",
       "      <td>-0.019364</td>\n",
       "      <td>-0.014105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024010211</td>\n",
       "      <td>0.420579</td>\n",
       "      <td>0.419274</td>\n",
       "      <td>0.395721</td>\n",
       "      <td>0.287102</td>\n",
       "      <td>0.397664</td>\n",
       "      <td>0.080878</td>\n",
       "      <td>0.071155</td>\n",
       "      <td>-0.328331</td>\n",
       "      <td>0.025927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2024010212</td>\n",
       "      <td>0.303101</td>\n",
       "      <td>0.270425</td>\n",
       "      <td>0.627370</td>\n",
       "      <td>0.427144</td>\n",
       "      <td>-0.351468</td>\n",
       "      <td>0.055349</td>\n",
       "      <td>-0.199494</td>\n",
       "      <td>-0.019364</td>\n",
       "      <td>-0.001072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2024010213</td>\n",
       "      <td>0.238786</td>\n",
       "      <td>0.273890</td>\n",
       "      <td>0.768499</td>\n",
       "      <td>0.733780</td>\n",
       "      <td>-0.146551</td>\n",
       "      <td>-0.042440</td>\n",
       "      <td>-0.154335</td>\n",
       "      <td>-0.019364</td>\n",
       "      <td>-0.059952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2024010214</td>\n",
       "      <td>0.328714</td>\n",
       "      <td>0.321078</td>\n",
       "      <td>0.455962</td>\n",
       "      <td>0.392139</td>\n",
       "      <td>-0.251225</td>\n",
       "      <td>0.043554</td>\n",
       "      <td>-0.119616</td>\n",
       "      <td>-0.019364</td>\n",
       "      <td>0.005469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9771</th>\n",
       "      <td>9771</td>\n",
       "      <td>2023123110</td>\n",
       "      <td>0.754154</td>\n",
       "      <td>0.209154</td>\n",
       "      <td>0.036692</td>\n",
       "      <td>0.938465</td>\n",
       "      <td>1.673459</td>\n",
       "      <td>0.982934</td>\n",
       "      <td>1.215863</td>\n",
       "      <td>0.998393</td>\n",
       "      <td>1.027639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9772</th>\n",
       "      <td>9772</td>\n",
       "      <td>2023123111</td>\n",
       "      <td>0.986851</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>0.010840</td>\n",
       "      <td>0.411787</td>\n",
       "      <td>0.650698</td>\n",
       "      <td>0.845767</td>\n",
       "      <td>0.753560</td>\n",
       "      <td>0.904055</td>\n",
       "      <td>0.836438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9773</th>\n",
       "      <td>9773</td>\n",
       "      <td>2023123112</td>\n",
       "      <td>0.944886</td>\n",
       "      <td>0.003691</td>\n",
       "      <td>0.051423</td>\n",
       "      <td>0.908719</td>\n",
       "      <td>1.376934</td>\n",
       "      <td>1.053047</td>\n",
       "      <td>1.382885</td>\n",
       "      <td>0.998393</td>\n",
       "      <td>1.106406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9774</th>\n",
       "      <td>9774</td>\n",
       "      <td>2023123113</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>0.651639</td>\n",
       "      <td>0.347403</td>\n",
       "      <td>0.393351</td>\n",
       "      <td>-1.758818</td>\n",
       "      <td>-1.007822</td>\n",
       "      <td>-1.474893</td>\n",
       "      <td>-0.328331</td>\n",
       "      <td>-1.005151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9775</th>\n",
       "      <td>9775</td>\n",
       "      <td>2023123114</td>\n",
       "      <td>0.553383</td>\n",
       "      <td>0.154653</td>\n",
       "      <td>0.291964</td>\n",
       "      <td>0.492621</td>\n",
       "      <td>0.529885</td>\n",
       "      <td>0.982934</td>\n",
       "      <td>0.800876</td>\n",
       "      <td>0.904055</td>\n",
       "      <td>0.939313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9776 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Date_hourly  weighted_positive_fb  weighted_negative_fb  \\\n",
       "0              0   2024010210              0.309803              0.280714   \n",
       "1              1   2024010211              0.420579              0.419274   \n",
       "2              2   2024010212              0.303101              0.270425   \n",
       "3              3   2024010213              0.238786              0.273890   \n",
       "4              4   2024010214              0.328714              0.321078   \n",
       "...          ...          ...                   ...                   ...   \n",
       "9771        9771   2023123110              0.754154              0.209154   \n",
       "9772        9772   2023123111              0.986851              0.002308   \n",
       "9773        9773   2023123112              0.944886              0.003691   \n",
       "9774        9774   2023123113              0.000958              0.651639   \n",
       "9775        9775   2023123114              0.553383              0.154653   \n",
       "\n",
       "      weighted_neutral_fb  weighted_DocTone  PriceChange  RF_Predictions  \\\n",
       "0                0.604901          0.461378    -0.298581       -0.014183   \n",
       "1                0.395721          0.287102     0.397664        0.080878   \n",
       "2                0.627370          0.427144    -0.351468        0.055349   \n",
       "3                0.768499          0.733780    -0.146551       -0.042440   \n",
       "4                0.455962          0.392139    -0.251225        0.043554   \n",
       "...                   ...               ...          ...             ...   \n",
       "9771             0.036692          0.938465     1.673459        0.982934   \n",
       "9772             0.010840          0.411787     0.650698        0.845767   \n",
       "9773             0.051423          0.908719     1.376934        1.053047   \n",
       "9774             0.347403          0.393351    -1.758818       -1.007822   \n",
       "9775             0.291964          0.492621     0.529885        0.982934   \n",
       "\n",
       "      XGBoost_Predictions  DecisionTree_Predictions  y_ensemble  \n",
       "0               -0.010086                 -0.019364   -0.014105  \n",
       "1                0.071155                 -0.328331    0.025927  \n",
       "2               -0.199494                 -0.019364   -0.001072  \n",
       "3               -0.154335                 -0.019364   -0.059952  \n",
       "4               -0.119616                 -0.019364    0.005469  \n",
       "...                   ...                       ...         ...  \n",
       "9771             1.215863                  0.998393    1.027639  \n",
       "9772             0.753560                  0.904055    0.836438  \n",
       "9773             1.382885                  0.998393    1.106406  \n",
       "9774            -1.474893                 -0.328331   -1.005151  \n",
       "9775             0.800876                  0.904055    0.939313  \n",
       "\n",
       "[9776 rows x 11 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('QQQ_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
